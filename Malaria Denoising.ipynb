{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2815d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e2de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_noise = \"D:\\\\Work\\\\My work\\\\ammar\\\\Dataset\\\\Log_Transform_Dataset\\\\Train\"\n",
    "test_dir_noise = \"D:\\\\Work\\\\My work\\\\ammar\\\\Dataset\\\\Log_Transform_Dataset\\\\Test\"\n",
    "\n",
    "train_dir_clean = \"D:\\\\Work\\\\My work\\\\ammar\\\\Dataset\\\\Renamed_Dataset\\\\Train\"\n",
    "test_dir_clean = \"D:\\\\Work\\\\My work\\\\ammar\\\\Dataset\\\\Renamed_Dataset\\\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5300eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8e48ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_noise = data_gen.flow_from_directory(\n",
    "    train_dir_noise,\n",
    "    target_size=(228, 228),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee40050",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset_noise)):\n",
    "    batch = train_dataset_noise[i]\n",
    "    train_noise_images, train_clean_labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95beec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_clean = data_gen.flow_from_directory(\n",
    "    train_dir_clean,\n",
    "    target_size=(228, 228),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e9a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset_clean)):\n",
    "    batch = train_dataset_clean[i]\n",
    "    train_clean_images, train_clean_labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf950ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset_noise = data_gen.flow_from_directory(\n",
    "    test_dir_noise,\n",
    "    target_size=(228, 228),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25890683",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_dataset_noise)):\n",
    "    batch = test_dataset_noise[i]\n",
    "    test_noise_images, test_noise_labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fccc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset_clean = data_gen.flow_from_directory(\n",
    "    test_dir_clean,\n",
    "    target_size=(228, 228),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a9b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_dataset_clean)):\n",
    "    batch = test_dataset_clean[i]\n",
    "    test_clean_images, test_clean_labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c858af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edae3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "                    # encoder network\n",
    "                    keras.Input(shape=(228, 228, 3)),\n",
    "                    Conv2D(32, kernel_size = (3,3), activation='relu', padding='same'),\n",
    "                    MaxPooling2D(2, padding='same'),\n",
    "                    Conv2D(16, 3, activation='relu', padding='same'),\n",
    "                    MaxPooling2D(2, padding='same'),\n",
    "\n",
    "                    # decoder network\n",
    "                    Conv2D(16, kernel_size = (3,3), activation='relu', padding='same'),\n",
    "                    UpSampling2D(2),\n",
    "                    Conv2D(32, 3, activation='relu', padding='same'),\n",
    "                    UpSampling2D(2),\n",
    "                    # output layer\n",
    "                    Conv2D(3, 3, activation='sigmoid', padding='same')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09d3175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 228, 228, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 114, 114, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 114, 114, 16)      4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 57, 57, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 57, 57, 16)        2320      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 114, 114, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 114, 114, 32)      4640      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 228, 228, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 228, 228, 3)       867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13347 (52.14 KB)\n",
      "Trainable params: 13347 (52.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8be2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c80138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6930 - accuracy: 0.6329 - val_loss: 0.6900 - val_accuracy: 0.8302\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6902 - accuracy: 0.7548 - val_loss: 0.6873 - val_accuracy: 0.8928\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6877 - accuracy: 0.8121 - val_loss: 0.6841 - val_accuracy: 0.9175\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6846 - accuracy: 0.8352 - val_loss: 0.6795 - val_accuracy: 0.9230\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6804 - accuracy: 0.8408 - val_loss: 0.6745 - val_accuracy: 0.9249\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6760 - accuracy: 0.8423 - val_loss: 0.6691 - val_accuracy: 0.9255\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6714 - accuracy: 0.8427 - val_loss: 0.6644 - val_accuracy: 0.9259\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6676 - accuracy: 0.8431 - val_loss: 0.6597 - val_accuracy: 0.9260\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6642 - accuracy: 0.8431 - val_loss: 0.6552 - val_accuracy: 0.9258\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6606 - accuracy: 0.8430 - val_loss: 0.6494 - val_accuracy: 0.9257\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6555 - accuracy: 0.8429 - val_loss: 0.6454 - val_accuracy: 0.9254\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6510 - accuracy: 0.8428 - val_loss: 0.6385 - val_accuracy: 0.9250\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6466 - accuracy: 0.8424 - val_loss: 0.6352 - val_accuracy: 0.9253\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6424 - accuracy: 0.8426 - val_loss: 0.6282 - val_accuracy: 0.9251\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6388 - accuracy: 0.8424 - val_loss: 0.6277 - val_accuracy: 0.9258\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6360 - accuracy: 0.8429 - val_loss: 0.6203 - val_accuracy: 0.9252\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6330 - accuracy: 0.8425 - val_loss: 0.6182 - val_accuracy: 0.9250\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6302 - accuracy: 0.8423 - val_loss: 0.6188 - val_accuracy: 0.9246\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6303 - accuracy: 0.8419 - val_loss: 0.6136 - val_accuracy: 0.9230\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6299 - accuracy: 0.8404 - val_loss: 0.6113 - val_accuracy: 0.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29a1744c7f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_noise_images, train_clean_images, batch_size = None, epochs=20, validation_data=(test_noise_images, test_clean_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56abb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D:\\\\Work\\\\My work\\\\ammar\\\\Dataset\\\\Log_Transform_Dataset\\\\Test\\\\Parasite\\\\33.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (228, 228))\n",
    "image = image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c85ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_output = model.predict(np.expand_dims(image, axis=0))\n",
    "predicted_output = np.squeeze(predicted_output, axis=0)\n",
    "predicted_output = cv2.cvtColor(predicted_output, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display the predicted output\n",
    "cv2.imshow('Predicted Output', predicted_output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
